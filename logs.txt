11:56:52,195 etl_logger INFO PySpark Session Created!
11:56:52,622 botocore.credentials INFO Found credentials in environment variables.
11:56:56,812 botocore.credentials INFO Found credentials in environment variables.
11:57:11,303 etl_logger INFO PySpark Session Created!
11:57:11,307 py4j.clientserver INFO Closing down clientserver connection
12:27:02,330 etl_logger INFO PySpark Session Created!
12:27:02,740 botocore.credentials INFO Found credentials in environment variables.
12:27:06,800 botocore.credentials INFO Found credentials in environment variables.
12:27:15,197 etl_logger INFO PySpark Session Created!
12:27:24,962 py4j.clientserver INFO Closing down clientserver connection
12:30:36,832 etl_logger INFO PySpark Session Created!
12:30:37,242 botocore.credentials INFO Found credentials in environment variables.
12:30:41,204 botocore.credentials INFO Found credentials in environment variables.
12:30:49,704 etl_logger INFO PySpark Session Created!
12:31:03,511 py4j.clientserver INFO Closing down clientserver connection
13:00:49,521 etl_logger INFO PySpark Session Created!
13:00:49,930 botocore.credentials INFO Found credentials in environment variables.
13:00:54,27 botocore.credentials INFO Found credentials in environment variables.
13:01:02,784 etl_logger INFO PySpark Session Created!
13:01:16,999 py4j.clientserver INFO Closing down clientserver connection
13:04:46,246 etl_logger INFO PySpark Session Created!
13:04:46,683 botocore.credentials INFO Found credentials in environment variables.
13:04:50,610 botocore.credentials INFO Found credentials in environment variables.
13:04:59,288 etl_logger INFO PySpark Session Created!
13:05:09,901 py4j.clientserver INFO Closing down clientserver connection
13:10:51,461 etl_logger INFO PySpark Session Created!
13:10:51,887 botocore.credentials INFO Found credentials in environment variables.
13:10:55,909 botocore.credentials INFO Found credentials in environment variables.
13:11:04,454 etl_logger INFO PySpark Session Created!
13:11:18,354 py4j.clientserver INFO Closing down clientserver connection
13:19:27,606 etl_logger INFO PySpark Session Created!
13:19:56,835 py4j.clientserver INFO Closing down clientserver connection
13:50:14,4 etl_logger INFO PySpark Session Created!
13:50:43,530 py4j.clientserver INFO Closing down clientserver connection
13:59:44,775 etl_logger INFO PySpark Session Created!
14:00:14,318 py4j.clientserver INFO Closing down clientserver connection
14:01:53,74 etl_logger INFO PySpark Session Created!
14:02:05,421 py4j.clientserver INFO Closing down clientserver connection
14:11:06,467 etl_logger INFO PySpark Session Created!
14:11:36,118 py4j.clientserver INFO Closing down clientserver connection
14:18:05,226 etl_logger INFO PySpark Session Created!
14:18:48,875 py4j.clientserver INFO Closing down clientserver connection
14:41:47,754 etl_logger INFO PySpark Session Created!
14:42:00,743 py4j.clientserver INFO Closing down clientserver connection
14:44:10,313 etl_logger INFO PySpark Session Created!
14:44:52,484 py4j.clientserver INFO Closing down clientserver connection
14:47:02,711 etl_logger INFO PySpark Session Created!
14:47:44,906 py4j.clientserver INFO Closing down clientserver connection
14:49:47,883 etl_logger INFO PySpark Session Created!
14:50:01,280 py4j.clientserver INFO Closing down clientserver connection
14:52:57,831 etl_logger INFO PySpark Session Created!
14:53:10,374 py4j.clientserver INFO Closing down clientserver connection
14:54:06,388 etl_logger INFO PySpark Session Created!
14:54:19,737 py4j.clientserver INFO Closing down clientserver connection
14:56:57,917 etl_logger INFO PySpark Session Created!
14:57:16,758 py4j.clientserver INFO Closing down clientserver connection
15:15:33,128 etl_logger INFO PySpark Session Created!
15:15:53,52 py4j.clientserver INFO Closing down clientserver connection
15:22:19,235 etl_logger INFO PySpark Session Created!
15:22:45,52 py4j.clientserver INFO Closing down clientserver connection
15:35:30,222 etl_logger INFO PySpark Session Created!
15:35:41,508 py4j.clientserver INFO Closing down clientserver connection
15:46:36,556 etl_logger INFO PySpark Session Created!
15:46:47,932 py4j.clientserver INFO Closing down clientserver connection
15:52:56,645 etl_logger INFO PySpark Session Created!
15:53:11,814 py4j.clientserver INFO Closing down clientserver connection
15:56:47,889 etl_logger INFO PySpark Session Created!
15:57:02,32 py4j.clientserver INFO Closing down clientserver connection
16:04:43,216 etl_logger INFO PySpark Session Created!
16:05:04,80 py4j.clientserver INFO Closing down clientserver connection
16:11:22,39 etl_logger INFO PySpark Session Created!
16:11:43,884 py4j.clientserver INFO Closing down clientserver connection
16:25:30,254 etl_logger INFO PySpark Session Created!
16:25:51,876 py4j.clientserver INFO Closing down clientserver connection
16:29:57,153 etl_logger INFO PySpark Session Created!
16:30:20,920 py4j.clientserver INFO Closing down clientserver connection
16:37:29,937 etl_logger INFO PySpark Session Created!
16:37:52,22 etl_logger INFO PySpark Session Created!
16:38:05,36 py4j.clientserver INFO Closing down clientserver connection
16:38:52,435 etl_logger INFO PySpark Session Created!
16:39:14,318 etl_logger INFO PySpark Session Created!
16:39:26,565 py4j.clientserver INFO Closing down clientserver connection
10:02:57,481 etl_logger INFO PySpark Session Created!
10:03:23,989 etl_logger INFO PySpark Session Created!
10:03:31,188 py4j.clientserver INFO Closing down clientserver connection
10:05:28,639 etl_logger INFO PySpark Session Created!
10:05:40,949 etl_logger INFO PySpark Session Created!
10:05:57,3 py4j.clientserver INFO Closing down clientserver connection
10:08:09,393 etl_logger INFO PySpark Session Created!
10:08:20,152 etl_logger INFO PySpark Session Created!
10:08:35,320 py4j.clientserver INFO Closing down clientserver connection
10:10:53,190 etl_logger INFO PySpark Session Created!
10:11:04,602 etl_logger INFO PySpark Session Created!
10:11:20,910 py4j.clientserver INFO Closing down clientserver connection
10:13:46,879 etl_logger INFO PySpark Session Created!
10:13:58,197 etl_logger INFO PySpark Session Created!
10:14:15,376 py4j.clientserver INFO Closing down clientserver connection
10:15:11,246 etl_logger INFO PySpark Session Created!
10:15:23,532 etl_logger INFO PySpark Session Created!
10:15:41,452 py4j.clientserver INFO Closing down clientserver connection
10:16:36,200 etl_logger INFO PySpark Session Created!
10:16:54,594 etl_logger INFO PySpark Session Created!
10:17:00,229 py4j.clientserver INFO Closing down clientserver connection
10:29:51,563 etl_logger INFO PySpark Session Created!
10:29:51,569 py4j.clientserver INFO Closing down clientserver connection
10:31:26,288 etl_logger INFO PySpark Session Created!
10:31:26,293 py4j.clientserver INFO Closing down clientserver connection
10:36:55,328 etl_logger INFO PySpark Session Created!
10:37:13,793 py4j.clientserver INFO Closing down clientserver connection
10:44:38,310 etl_logger INFO PySpark Session Created!
10:44:38,315 py4j.clientserver INFO Closing down clientserver connection
10:45:28,633 etl_logger INFO PySpark Session Created!
10:45:43,410 py4j.clientserver INFO Closing down clientserver connection
10:52:20,359 etl_logger INFO PySpark Session Created!
10:52:34,222 etl_logger INFO Schema check OK.
10:52:45,296 etl_logger INFO Data rows are identical!
10:52:45,319 py4j.clientserver INFO Closing down clientserver connection
10:53:53,896 etl_logger INFO PySpark Session Created!
10:54:19,612 py4j.clientserver INFO Closing down clientserver connection
10:56:00,27 etl_logger INFO PySpark Session Created!
10:56:22,546 py4j.clientserver INFO Closing down clientserver connection
10:57:01,483 etl_logger INFO PySpark Session Created!
10:57:24,37 py4j.clientserver INFO Closing down clientserver connection
10:57:42,868 etl_logger INFO PySpark Session Created!
10:57:57,634 py4j.clientserver INFO Closing down clientserver connection
12:30:12,865 etl_logger INFO PySpark Session Created!
12:30:38,655 py4j.clientserver INFO Closing down clientserver connection
15:14:46,763 etl_logger INFO PySpark Session Created!
15:15:00,143 py4j.clientserver INFO Closing down clientserver connection
16:32:26,188 etl_logger INFO PySpark Session Created!
16:32:33,468 py4j.clientserver INFO Error while sending or receiving.
Traceback (most recent call last):
  File "C:\Users\Oleksandr Forkun\AppData\Local\Programs\Python\Python39\lib\socket.py", line 704, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Spark\spark-3.2.2-bin-hadoop2.7\python\lib\py4j-0.10.9.5-src.zip\py4j\clientserver.py", line 503, in send_command
    self.socket.sendall(command.encode("utf-8"))
ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host
16:32:33,469 py4j.clientserver INFO Closing down clientserver connection
16:32:33,470 root INFO Exception while sending command.
Traceback (most recent call last):
  File "C:\Users\Oleksandr Forkun\AppData\Local\Programs\Python\Python39\lib\socket.py", line 704, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Spark\spark-3.2.2-bin-hadoop2.7\python\lib\py4j-0.10.9.5-src.zip\py4j\clientserver.py", line 503, in send_command
    self.socket.sendall(command.encode("utf-8"))
ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Spark\spark-3.2.2-bin-hadoop2.7\python\lib\py4j-0.10.9.5-src.zip\py4j\java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "C:\Spark\spark-3.2.2-bin-hadoop2.7\python\lib\py4j-0.10.9.5-src.zip\py4j\clientserver.py", line 506, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending
16:32:33,664 py4j.clientserver INFO Error while sending or receiving.
Traceback (most recent call last):
  File "C:\Spark\spark-3.2.2-bin-hadoop2.7\python\lib\py4j-0.10.9.5-src.zip\py4j\clientserver.py", line 503, in send_command
    self.socket.sendall(command.encode("utf-8"))
ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host
16:32:33,664 py4j.clientserver INFO Closing down clientserver connection
16:32:33,666 root INFO Exception while sending command.
Traceback (most recent call last):
  File "C:\Spark\spark-3.2.2-bin-hadoop2.7\python\lib\py4j-0.10.9.5-src.zip\py4j\clientserver.py", line 503, in send_command
    self.socket.sendall(command.encode("utf-8"))
ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Spark\spark-3.2.2-bin-hadoop2.7\python\lib\py4j-0.10.9.5-src.zip\py4j\java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "C:\Spark\spark-3.2.2-bin-hadoop2.7\python\lib\py4j-0.10.9.5-src.zip\py4j\clientserver.py", line 506, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending
16:32:35,501 py4j.clientserver INFO Closing down clientserver connection
16:32:35,501 py4j.clientserver INFO Error while receiving.
Traceback (most recent call last):
  File "C:\Users\Oleksandr Forkun\AppData\Local\Programs\Python\Python39\lib\socket.py", line 704, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Spark\spark-3.2.2-bin-hadoop2.7\python\lib\py4j-0.10.9.5-src.zip\py4j\clientserver.py", line 503, in send_command
    self.socket.sendall(command.encode("utf-8"))
ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Spark\spark-3.2.2-bin-hadoop2.7\python\lib\py4j-0.10.9.5-src.zip\py4j\java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "C:\Spark\spark-3.2.2-bin-hadoop2.7\python\lib\py4j-0.10.9.5-src.zip\py4j\clientserver.py", line 506, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Spark\spark-3.2.2-bin-hadoop2.7\python\lib\py4j-0.10.9.5-src.zip\py4j\clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "C:\Users\Oleksandr Forkun\AppData\Local\Programs\Python\Python39\lib\socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "C:\Spark\spark-3.2.2-bin-hadoop2.7\python\pyspark\context.py", line 292, in signal_handler
    self.cancelAllJobs()
  File "C:\Spark\spark-3.2.2-bin-hadoop2.7\python\pyspark\context.py", line 1195, in cancelAllJobs
    self._jsc.sc().cancelAllJobs()
  File "C:\Spark\spark-3.2.2-bin-hadoop2.7\python\lib\py4j-0.10.9.5-src.zip\py4j\java_gateway.py", line 1320, in __call__
    answer = self.gateway_client.send_command(command)
  File "C:\Spark\spark-3.2.2-bin-hadoop2.7\python\lib\py4j-0.10.9.5-src.zip\py4j\java_gateway.py", line 1053, in send_command
    response = self.send_command(command, binary=binary)
  File "C:\Spark\spark-3.2.2-bin-hadoop2.7\python\lib\py4j-0.10.9.5-src.zip\py4j\java_gateway.py", line 1036, in send_command
    connection = self._get_connection()
  File "C:\Spark\spark-3.2.2-bin-hadoop2.7\python\lib\py4j-0.10.9.5-src.zip\py4j\clientserver.py", line 284, in _get_connection
    connection = self._create_new_connection()
  File "C:\Spark\spark-3.2.2-bin-hadoop2.7\python\lib\py4j-0.10.9.5-src.zip\py4j\clientserver.py", line 291, in _create_new_connection
    connection.connect_to_java_server()
  File "C:\Spark\spark-3.2.2-bin-hadoop2.7\python\lib\py4j-0.10.9.5-src.zip\py4j\clientserver.py", line 438, in connect_to_java_server
    self.socket.connect((self.java_address, self.java_port))
ConnectionRefusedError: [WinError 10061] No connection could be made because the target machine actively refused it
16:32:35,502 py4j.clientserver INFO Closing down clientserver connection
16:32:35,502 root ERROR Exception while sending command.
Traceback (most recent call last):
  File "C:\Users\Oleksandr Forkun\AppData\Local\Programs\Python\Python39\lib\socket.py", line 704, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Spark\spark-3.2.2-bin-hadoop2.7\python\lib\py4j-0.10.9.5-src.zip\py4j\clientserver.py", line 503, in send_command
    self.socket.sendall(command.encode("utf-8"))
ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Spark\spark-3.2.2-bin-hadoop2.7\python\lib\py4j-0.10.9.5-src.zip\py4j\java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "C:\Spark\spark-3.2.2-bin-hadoop2.7\python\lib\py4j-0.10.9.5-src.zip\py4j\clientserver.py", line 506, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Spark\spark-3.2.2-bin-hadoop2.7\python\lib\py4j-0.10.9.5-src.zip\py4j\clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "C:\Users\Oleksandr Forkun\AppData\Local\Programs\Python\Python39\lib\socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "C:\Spark\spark-3.2.2-bin-hadoop2.7\python\pyspark\context.py", line 292, in signal_handler
    self.cancelAllJobs()
  File "C:\Spark\spark-3.2.2-bin-hadoop2.7\python\pyspark\context.py", line 1195, in cancelAllJobs
    self._jsc.sc().cancelAllJobs()
  File "C:\Spark\spark-3.2.2-bin-hadoop2.7\python\lib\py4j-0.10.9.5-src.zip\py4j\java_gateway.py", line 1320, in __call__
    answer = self.gateway_client.send_command(command)
  File "C:\Spark\spark-3.2.2-bin-hadoop2.7\python\lib\py4j-0.10.9.5-src.zip\py4j\java_gateway.py", line 1053, in send_command
    response = self.send_command(command, binary=binary)
  File "C:\Spark\spark-3.2.2-bin-hadoop2.7\python\lib\py4j-0.10.9.5-src.zip\py4j\java_gateway.py", line 1036, in send_command
    connection = self._get_connection()
  File "C:\Spark\spark-3.2.2-bin-hadoop2.7\python\lib\py4j-0.10.9.5-src.zip\py4j\clientserver.py", line 284, in _get_connection
    connection = self._create_new_connection()
  File "C:\Spark\spark-3.2.2-bin-hadoop2.7\python\lib\py4j-0.10.9.5-src.zip\py4j\clientserver.py", line 291, in _create_new_connection
    connection.connect_to_java_server()
  File "C:\Spark\spark-3.2.2-bin-hadoop2.7\python\lib\py4j-0.10.9.5-src.zip\py4j\clientserver.py", line 438, in connect_to_java_server
    self.socket.connect((self.java_address, self.java_port))
ConnectionRefusedError: [WinError 10061] No connection could be made because the target machine actively refused it

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Spark\spark-3.2.2-bin-hadoop2.7\python\lib\py4j-0.10.9.5-src.zip\py4j\java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "C:\Spark\spark-3.2.2-bin-hadoop2.7\python\lib\py4j-0.10.9.5-src.zip\py4j\clientserver.py", line 539, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
16:32:35,503 py4j.clientserver INFO Closing down clientserver connection
16:32:35,503 py4j.clientserver INFO Closing down clientserver connection
16:32:58,157 etl_logger INFO PySpark Session Created!
16:33:19,674 etl_logger INFO Data has been written to Postgresql DB table!
16:33:21,888 py4j.clientserver INFO Closing down clientserver connection
16:38:13,564 etl_logger INFO PySpark Session Created!
16:38:37,301 etl_logger INFO Data has been written to Postgresql DB table!
16:38:39,687 py4j.clientserver INFO Closing down clientserver connection
16:39:37,467 etl_logger INFO PySpark Session Created!
16:40:00,384 etl_logger INFO Data has been written to Postgresql DB table!
16:40:02,620 py4j.clientserver INFO Closing down clientserver connection
16:43:44,135 etl_logger INFO PySpark Session Created!
16:44:06,560 etl_logger INFO Data has been written to Postgresql DB table!
16:44:08,836 py4j.clientserver INFO Closing down clientserver connection
16:46:44,749 etl_logger INFO PySpark Session Created!
16:47:08,970 etl_logger INFO Data has been written to Postgresql DB table!
16:47:11,303 py4j.clientserver INFO Closing down clientserver connection
